---
title: 'iteration'
description: '반복'
categories:
  - labml.ai Annotated Pytorch Paper Implementations
url: https://nn.labml.ai
---
<a href="https://nn.labml.ai/" target="_blank"><img   loading="lazy" alt="src: labml.ai" src="https://img.shields.io/badge/문서-labml.ai_Annoated_Pytorch_Paper_Implementations-deeppink" ></a>
---
1 epoch(에폭)을 마치는 데 필요한 미니 배치의 수입니다. 하나의 epoch에 대해서 몇번 반복해서 학습할 지 나타내는 횟수입니다. 

예를 들어 1500개의 데이터에 대해서 배치 사이즈 100으로 15개의 미니 배치로 나누었을 때 1 에폭을 완료 하기 위해서는 15-iteration 반복이 필요하며 15번의 파라미터 업데이트가 진행 됩니다

## 참조

1. https://losskatsu.github.io/machine-learning/epoch-batch/#3-epoch%EC%9D%98-%EC%9D%98%EB%AF%B8
