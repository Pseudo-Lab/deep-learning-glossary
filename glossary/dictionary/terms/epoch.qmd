---
title: 'epoch'
description: '에폭'
categories:
  - Huggingface Transformer
url: https://huggingface.co/docs/transformers/index
---
<a href="https://huggingface.co/docs/transformers/index" target="_blank"><img   loading="lazy" alt="src: HuggingFace Transformer" src="https://img.shields.io/badge/문서-Huggingface_Transformer-blue" ></a>
---
딥러닝에서 에폭은 모델의 훈련량을 나타내는 단위로, 1 에폭은 학습 데이터 전체를 한 번 순회하는 것을 의미합니다.

모델 훈련 시 학습 데이터는 배치라고 부르는 데이터 묶음으로 나뉘어 모델에 전달됩니다. 따라서 배치 크기에 따라서 1 에폭에 모델이 훈련되는 횟수가 달라집니다.

예를 들어 학습 데이터의 총 샘플 수가 100이고 배치 크기가 10이라면 1 에폭당 10회의 훈련이 진행됩니다.

## 참조

1. https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch