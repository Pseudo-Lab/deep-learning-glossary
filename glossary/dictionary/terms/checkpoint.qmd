---
title: 'checkpoint'
description: '체크포인트'
url: https://huggingface.co/docs/transformers/index
---
<a href="https://huggingface.co/docs/transformers/index" target="_blank"><img   loading="lazy" alt="src: HuggingFace Transformer" src="https://img.shields.io/badge/문서-Huggingface_Transformer-blue" ></a>
---

딥러닝에서 "checkpoint"란 모델의 중간 상태나 가중치(weight) 및 다른 학습 관련 정보를 저장하는 용어입니다. 이것은 모델 학습 중에 모델의 파라미터 및 학습 과정을 백업하고 모델을 재사용하거나 학습을 다시 시작할 때 사용됩니다. "checkpoint"는 다음과 같은 의미와 목적을 가지고 있습니다:

모델 복원 및 재사용: 모델 학습 중에 정기적으로 checkpoint를 저장하면 모델의 중간 상태를 나중에 복원하고 재사용할 수 있습니다. 이것은 학습 프로세스를 중단하고 나중에 중단된 곳에서 다시 시작할 때 유용합니다. 예를 들어, 모델 학습이 오랜 시간이 걸리는 경우, 학습이 중간에 실패하거나 중단된 경우, checkpoint를 사용하여 마지막으로 저장된 상태에서 학습을 재개할 수 있습니다.


## 참조

1. Chatgpt3.5. (2023, 10월 8일). OpenAI. [딥러닝 checkpoint의 의미]. https://chat.openai.com/


